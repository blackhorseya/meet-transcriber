/**
 * Offscreen Document
 * MV3 æž¶æ§‹ï¼šè² è²¬éŸ³è¨Šæ•ç²å’ŒéŒ„è£½
 *
 * æµç¨‹ï¼š
 * 1. æŽ¥æ”¶ START_CAPTURE è¨Šæ¯ï¼ˆåŒ…å« streamIdï¼‰
 * 2. ä½¿ç”¨ getUserMedia + chromeMediaSource: 'tab' å–å¾— Tab éŸ³è¨Š
 * 3. å¦‚æžœå•Ÿç”¨éº¥å…‹é¢¨ï¼Œç”¨ AudioContext æ··åˆå…©å€‹éŸ³æº
 * 4. å»ºç«‹ AudioContext å›žæ”¾ï¼ˆè®“ä½¿ç”¨è€…èƒ½è½åˆ°å°æ–¹è²éŸ³ï¼‰
 * 5. ä½¿ç”¨ MediaRecorder éŒ„è£½ï¼ˆæ··åˆå¾Œçš„ï¼‰éŸ³è¨Š
 * 6. åœæ­¢æ™‚åˆä½µæ‰€æœ‰ chunks ä¸¦é–‹å•ŸéŸ³è¨Šæª”
 */

import type { StartCapture } from '@/lib/message-types';

console.log('[Offscreen] === OFFSCREEN DOCUMENT LOADED ===');

// ============================================
// ç‹€æ…‹
// ============================================

let mediaRecorder: MediaRecorder | null = null;
let recordedChunks: Blob[] = [];
let tabStream: MediaStream | null = null;
let micStream: MediaStream | null = null;
let mixingContext: AudioContext | null = null;
let playbackContext: AudioContext | null = null;

// ============================================
// Message Handling
// ============================================

chrome.runtime.onMessage.addListener((msg: unknown) => {
  const message = msg as { type: string };
  console.log('[Offscreen] Received message:', message.type);

  switch (message.type) {
    case 'START_CAPTURE':
      handleStartCapture(msg as StartCapture);
      break;
    case 'STOP_CAPTURE':
      handleStopCapture();
      break;
  }

  return false;
});

// ============================================
// Capture Control
// ============================================

async function handleStartCapture(message: StartCapture): Promise<void> {
  if (mediaRecorder?.state === 'recording') {
    console.log('[Offscreen] Already recording, ignoring start request');
    return;
  }

  const { streamId, includeMicrophone, microphoneDeviceLabel } = message;

  console.log('[Offscreen] Starting capture:', {
    streamId: streamId.substring(0, 20) + '...',
    includeMicrophone,
    microphoneDeviceLabel,
  });

  try {
    // ðŸ”‘ Step 1: å–å¾— Tab éŸ³è¨Šï¼ˆå°æ–¹çš„è²éŸ³ï¼‰
    tabStream = await navigator.mediaDevices.getUserMedia({
      audio: {
        // @ts-expect-error - Chrome-specific constraints
        mandatory: {
          chromeMediaSource: 'tab',
          chromeMediaSourceId: streamId,
        },
      },
    });

    console.log('[Offscreen] Got Tab stream:', {
      tracks: tabStream.getAudioTracks().length,
      enabled: tabStream.getAudioTracks()[0]?.enabled,
    });

    // ðŸ”‘ Step 2: å›žæ”¾ Tab éŸ³è¨Šï¼Œè®“ä½¿ç”¨è€…èƒ½è½åˆ°å°æ–¹è²éŸ³
    playbackContext = new AudioContext();
    if (playbackContext.state === 'suspended') {
      await playbackContext.resume();
    }
    const playbackSource = playbackContext.createMediaStreamSource(tabStream);
    playbackSource.connect(playbackContext.destination);
    console.log('[Offscreen] Tab audio playback connected, state:', playbackContext.state);

    // ðŸ”‘ Step 3: æ±ºå®šè¦éŒ„è£½çš„ stream
    let streamToRecord: MediaStream;

    if (includeMicrophone) {
      console.log('[Offscreen] Attempting to get microphone...');
      try {
        // ðŸ”‘ æ ¹æ“š label æ‰¾åˆ°å°æ‡‰çš„ deviceId
        let micDeviceId: string | undefined;
        if (microphoneDeviceLabel) {
          const devices = await navigator.mediaDevices.enumerateDevices();
          const micDevice = devices.find(
            d => d.kind === 'audioinput' && d.label === microphoneDeviceLabel
          );
          if (micDevice) {
            micDeviceId = micDevice.deviceId;
            console.log('[Offscreen] Found microphone device:', {
              label: micDevice.label,
              deviceId: micDeviceId.substring(0, 20) + '...',
            });
          } else {
            console.warn('[Offscreen] Microphone device not found by label:', microphoneDeviceLabel);
          }
        }

        // å–å¾—éº¥å…‹é¢¨ï¼ˆä½¿ç”¨æŒ‡å®šçš„ deviceId æˆ–é è¨­ï¼‰
        micStream = await navigator.mediaDevices.getUserMedia({
          audio: {
            deviceId: micDeviceId ? { exact: micDeviceId } : undefined,
            echoCancellation: false,  // ä¸è¦æ¶ˆé™¤å›žéŸ³ï¼Œæˆ‘å€‘æƒ³éŒ„åˆ°è‡ªå·±çš„è²éŸ³
            noiseSuppression: true,
            autoGainControl: true,
          },
        });

        console.log('[Offscreen] Got Microphone stream:', {
          tracks: micStream.getAudioTracks().length,
          enabled: micStream.getAudioTracks()[0]?.enabled,
          label: micStream.getAudioTracks()[0]?.label,
        });

        // ðŸ”‘ Step 4: æ··åˆ Tab + éº¥å…‹é¢¨
        mixingContext = new AudioContext();
        
        // ðŸ”‘ é—œéµï¼šç¢ºä¿ AudioContext æ˜¯ running ç‹€æ…‹
        if (mixingContext.state === 'suspended') {
          await mixingContext.resume();
        }
        console.log('[Offscreen] Mixing AudioContext state:', mixingContext.state);
        console.log('[Offscreen] Mixing AudioContext sampleRate:', mixingContext.sampleRate);

        const mixedDest = mixingContext.createMediaStreamDestination();

        // é€£æŽ¥ Tab éŸ³è¨Šåˆ°æ··éŸ³ç›®æ¨™ï¼ˆåŠ å…¥ GainNode æ–¹ä¾¿èª¿æ•´ï¼‰
        const tabSource = mixingContext.createMediaStreamSource(tabStream);
        const tabGain = mixingContext.createGain();
        tabGain.gain.value = 1.0;  // Tab éŸ³é‡æ­£å¸¸
        tabSource.connect(tabGain);
        tabGain.connect(mixedDest);

        // é€£æŽ¥éº¥å…‹é¢¨åˆ°æ··éŸ³ç›®æ¨™ï¼ˆåŠ å…¥ GainNode æ”¾å¤§ï¼‰
        const micSource = mixingContext.createMediaStreamSource(micStream);
        const micGain = mixingContext.createGain();
        micGain.gain.value = 2.0;  // ðŸ”‘ æ”¾å¤§éº¥å…‹é¢¨éŸ³é‡
        micSource.connect(micGain);
        micGain.connect(mixedDest);

        console.log('[Offscreen] Audio nodes connected with gain:', {
          tabGain: tabGain.gain.value,
          micGain: micGain.gain.value,
        });

        streamToRecord = mixedDest.stream;
        
        console.log('[Offscreen] Audio mixing complete:', {
          mixedTracks: streamToRecord.getAudioTracks().length,
          mixedTrackEnabled: streamToRecord.getAudioTracks()[0]?.enabled,
          mixedTrackMuted: streamToRecord.getAudioTracks()[0]?.muted,
        });

      } catch (micErr) {
        console.warn('[Offscreen] Microphone access failed, falling back to tab-only:', micErr);
        streamToRecord = tabStream;
      }
    } else {
      console.log('[Offscreen] Microphone disabled, using tab-only');
      streamToRecord = tabStream;
    }

    // ðŸ”‘ Step 5: é–‹å§‹éŒ„è£½
    recordedChunks = [];
    
    // Debug: ç¢ºèªä½¿ç”¨çš„æ˜¯å“ªå€‹ stream
    const isMixedStream = streamToRecord !== tabStream;
    console.log('[Offscreen] Recording stream:', {
      isMixedStream,
      streamId: streamToRecord.id,
      audioTracks: streamToRecord.getAudioTracks().map(t => ({
        id: t.id,
        label: t.label,
        enabled: t.enabled,
        muted: t.muted,
        readyState: t.readyState,
      })),
    });
    
    mediaRecorder = new MediaRecorder(streamToRecord, { mimeType: 'audio/webm;codecs=opus' });

    mediaRecorder.ondataavailable = (event) => {
      if (event.data.size > 0) {
        recordedChunks.push(event.data);
        console.log(`[Offscreen] Chunk: ${event.data.size} bytes, total: ${recordedChunks.length}`);
      }
    };

    mediaRecorder.onstop = () => {
      console.log('[Offscreen] MediaRecorder stopped, processing chunks...');

      if (recordedChunks.length === 0) {
        console.log('[Offscreen] No chunks recorded');
        return;
      }

      const audioBlob = new Blob(recordedChunks, { type: 'audio/webm' });
      console.log(`[Offscreen] Created audio blob: ${audioBlob.size} bytes`);

      window.open(URL.createObjectURL(audioBlob), '_blank');
      console.log('[Offscreen] Opened audio file in new tab');

      recordedChunks = [];
    };

    mediaRecorder.onerror = (event) => {
      console.error('[Offscreen] MediaRecorder error:', event);
    };

    mediaRecorder.start();
    console.log('[Offscreen] MediaRecorder started');

    chrome.runtime.sendMessage({ type: 'CAPTURE_STARTED' }).catch(console.error);
    window.location.hash = 'recording';

  } catch (err) {
    console.error('[Offscreen] Failed to start capture:', err);
    chrome.runtime.sendMessage({
      type: 'CAPTURE_ERROR',
      error: err instanceof Error ? err.message : 'ç„¡æ³•å–å¾—éŸ³è¨Š',
    }).catch(console.error);
  }
}

function handleStopCapture(): void {
  console.log('[Offscreen] Stopping capture');

  // åœæ­¢éŒ„è£½ï¼ˆæœƒè§¸ç™¼ onstop äº‹ä»¶ï¼‰
  if (mediaRecorder && mediaRecorder.state !== 'inactive') {
    mediaRecorder.stop();
  }

  // åœæ­¢ Tab éŸ³è»Œ
  if (tabStream) {
    tabStream.getTracks().forEach((t) => t.stop());
    tabStream = null;
  }

  // åœæ­¢éº¥å…‹é¢¨éŸ³è»Œ
  if (micStream) {
    micStream.getTracks().forEach((t) => t.stop());
    micStream = null;
  }

  // é—œé–‰ AudioContext
  if (mixingContext && mixingContext.state !== 'closed') {
    mixingContext.close().catch(console.error);
    mixingContext = null;
  }

  if (playbackContext && playbackContext.state !== 'closed') {
    playbackContext.close().catch(console.error);
    playbackContext = null;
  }

  mediaRecorder = null;
  window.location.hash = '';

  chrome.runtime.sendMessage({ type: 'CAPTURE_STOPPED' }).catch(console.error);
}

console.log('[Offscreen] Ready to receive capture commands');
